{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,re,csv\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = open(\"pride_prejudice_english.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = open(\"pride_prejudice_hindi_transliteration.txt\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_data = eng.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_data = hi.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yah saawvabhauik roop se sveekaar kiya gaya ek satya hai, ki ek saubhaagya ke lie ek akela vyakti, e'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data = data.replace('[^\\x00-\\x7F]+',' ')\n",
    "    data = ''.join(i for i in data if not i.isdigit())\n",
    "    data = re.sub('[^a-zA-Z \\s]', ' ', data)\n",
    "    data = data.lower()\n",
    "    #remove 's\n",
    "    data = re.sub('\\'s', ' ', data)\n",
    "    #remove n't\n",
    "    data = re.sub('n\\'t', ' ', data)\n",
    "    #remove 'm\n",
    "    data = re.sub('\\'m', ' ', data)\n",
    "    #remove 'd\n",
    "    data = re.sub('\\'d', ' ', data)\n",
    "    #remove 'll\n",
    "    data = re.sub('\\'ll', ' ', data)\n",
    "    #remove 're\n",
    "    data=re.sub('\\'re', ' ', data)\n",
    "    return data\n",
    "    data = data.replace('\\n',' ')\n",
    "    data = re.sub('[ ]+', ' ', data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eng_data = preprocess(eng_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_data = preprocess(hi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createbigramfrequency(data):\n",
    "    listofbigram = []\n",
    "    for i in range(len(data)):\n",
    "        if(len(data[i:i+2].strip())>1):\n",
    "            listofbigram.append(data[i:i+2])\n",
    "    unique = set(listofbigram)\n",
    "    dic = {}\n",
    "    for i in unique:\n",
    "        dic[i] = 0\n",
    "        for bi in listofbigram:\n",
    "            if i == bi:\n",
    "                dic[i] = dic[i]+1\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eng_bi = createbigramfrequency(eng_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hin_bi = createbigramfrequency(hi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/srovess/project:topic_modelling/tweets[semi_processed].csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_sen = []\n",
    "hin_sen = []\n",
    "for line in data:\n",
    "    eng_count =0\n",
    "    hin_count =0\n",
    "    for word in line.split(\" \"):\n",
    "        eng_fr = 0\n",
    "        hin_fr = 0\n",
    "        for i in range(len(word)):\n",
    "            if(len(word[i:i+2].strip())>1):\n",
    "                if(word[i:i+2] in eng_bi.keys()):\n",
    "                    eng_fr+= eng_bi[word[i:i+2]]\n",
    "                if(word[i:i+2] in hin_bi.keys()):\n",
    "                    hin_fr+= hin_bi[word[i:i+2]]\n",
    "        #print word , eng_fr, hin_fr\n",
    "        if(eng_fr>hin_fr):\n",
    "            eng_count+=1\n",
    "        if(hin_fr>eng_fr):\n",
    "            hin_count+=1\n",
    "    if(eng_count>hin_count):\n",
    "        eng_sen.append(line)\n",
    "    if(hin_count>eng_count):\n",
    "        hin_sen.append(line)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dipaligoenka alokkum dear mam had worked wil anjar years as deputy manager now when claim my epf its make issue in misspelt in my name mr alok misguided me to change name in adharcard pls help me to claim my epf online',\n",
       " 'how to check bank linking status of adhar for more than one bank adharcard uidai',\n",
       " 'dear sir please come to my village will share you my adharcard where you can get my details pic twitter com nv aodb',\n",
       " 'and modi is gonna give them adharcard you complaining to wrong person',\n",
       " 'adharcard pic twitter com xmjvqlvumc',\n",
       " 'sir what think that is political party and politician are the main obstacles of development works like by raising uncessery issue to fail or slowdown the works like rafale adharcard gst and many more why we are taking the unwanted burden of politicians why',\n",
       " 'adharcard basically model of incindia which is completely indians till may',\n",
       " 'rss dog squad still sitting in many offices to distract public work so people becom angry wth new govt in rajasthan municipal office jaipur adhar centre asked to give registery of house adharcard address proof refuse to take house light bill rss still barking aftr demise',\n",
       " 'am vexed of seeing this fucking yearschallenge posts can someone start adharcard pic challenge and voterid pic challenges note do want to participate in this challenge know that how shitty is my face in government id proofs',\n",
       " 'link ur adharcard with pugg']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_sen[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['digital seva central jariye madhyam warg ko luta ja raha hai adharcard updation pancard updation or any prakar sarkari papers bnavane jane wale logo ko jyada rs paid karwa kar unhe loot rahe hae digital seva center wale',\n",
       " 'sir mra papa ka adharcard banvya tha abi thak nahi aya',\n",
       " 'narendramodi sir day ho gaya firbhi aadharcard on prosses bata rahahe to admi benk account kaise khulvayega apne rasan card ko government pruf se nikal diyato jiska aadhar card nahi he wo kuch bhai kam nahi karsakta adharcard nhi banega tohamara kya hogasir humpicherahjayege',\n",
       " 'visa adharcard bhuthan nepal',\n",
       " 'honerable court ke adesh ki dhajjiya udha rahe hai adhaar card banane wale log rs lekar banaye ja rahe adharcard uidai ceo uidai uppolice agrapolice arunjaitley narendramodi pmoindia tarekfatah',\n",
       " 'adhar card adhar card adharcard app news techtalk',\n",
       " 'ab to twitter ki har ladki ko adharcard ki pic lagana padegi header par jise pata lag sake ki kahi dusri nandini to nahi hai',\n",
       " 'dosti adharcard phuk',\n",
       " 'gont aadhar authentication failed mail today hbki maine aisa kuch kiya hi nahi kya mere adhar card ko koi hack kar raha thaa help me narendramodi amitshah adharcard adharcard aadhaar uidai aadhaarcard in security hacking aadhaarhack helppic twitter com ch ogfx',\n",
       " 'adharcard cmofkarnataka siddaramaiah utkhader']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hin_sen[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create csv file which contains eng tweets\n",
    "for x in eng_sen:\n",
    "    with open('tweets[english].csv', 'a') as csvFile:\n",
    "                writer = csv.writer(csvFile)\n",
    "                writer.writerow(x.split(\",\"))\n",
    "    csvFile.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
